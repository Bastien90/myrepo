---
title: "Covid 19 Forecast"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Libraries and  Raw Data
```{r lib, message=FALSE, warning=FALSE}
library(googleVis)
#op <- options(gvis.plot.tag='chart')
library(lubridate)
library(fpp3)
library(tidyverse)
library(tsibble)
library(feasts)
library(ggplot2)
library(WDI)
library(DataExplorer)
library(recipes)
library(h2o)
library(tidymodels)
library(scales)
library(gridExtra)
library(highcharter)
library(GGally)
library(corrplot)
library(ggthemes)
library(zoo)
library(anomalize)
library(tidycovid19)

theme_set(theme_minimal())



covid <- read_csv("data/covid19.csv")

#download new data if available
if(max(covid$date) < today() -days(1) ){

  covid_new <- tidycovid19::download_jhu_csse_covid19_data()
  
  #additional check
  if(nrow(covid_new) > nrow(covid)){
  covid <- covid_new
  rm(covid_new)
  write_csv(covid, "data/covid19.csv")
  }
}

paste0("period covered: ", min(covid$date), " - ", max(covid$date)) %>% print()

#Goal to predict last two weeks
period <- 14

train <- covid %>% filter(date <= max(date) - days(14))

test <- covid %>% filter(date > max(date) - days(14))

paste0("train: ", min(train$date), " - ", max(train$date)) %>% print()
paste0("test: ", min(test$date), " - ", max(test$date)) %>% print()




set.seed(123)
sampled_id <- unique(train$country )[sample(1 : length(unique(train$country)), 10)]
sampled_id <- c(sampled_id, "Italy", "France", "Germany", "Sweden", "US", "Thailand", "China", "Afghanistan")

# train <- train %>% filter(country %in% sampled_id)
# 
# test <- test %>% filter(country %in% sampled_id)


```

# EDA and Additional World Bank Data

```{r EDA, results='asis', tidy=FALSE, message=FALSE, warning=FALSE}
#First detected case
day_of_first_case <-  train %>%
  filter(confirmed > 0) %>%
  group_by(iso3c) %>%
  summarise(day_of_first_case = min(date)) %>%
  ungroup()

train <- train %>%
         inner_join(day_of_first_case, by = "iso3c") %>%
          mutate(
          days_since_first_case = as.numeric(difftime(date, day_of_first_case, units ="days")),
          days_since_first_case =ifelse(days_since_first_case < 0, -1, days_since_first_case),
          days_since_global_outbreak  = as.numeric(difftime(date, min(date), units ="days")))


test <- test %>%
         inner_join(day_of_first_case, by = "iso3c") %>%
          mutate(
          days_since_first_case = as.numeric(difftime(date, day_of_first_case, units ="days")),
          days_since_first_case =ifelse(days_since_first_case < 0, -1, days_since_first_case),
          days_since_global_outbreak  = as.numeric(difftime(date, min(date), units ="days")))


train %>% filter(confirmed > 0) %>%
hchart(., "line", hcaes(x = days_since_first_case, y = confirmed, group = country))

#WDI Data
if(!file.exists("data/wdi_dat.csv")){
  wdi_dat <- WDI(indicator = c(
                               "SP.POP.TOTL",
                               "NY.GDP.PCAP.KD",
                               "SP.DYN.LE00.IN", 
                               "SP.DYN.IMRT.IN", 
                               "ST.INT.DPRT",
                               "ST.INT.ARVL",
                               "SH.MED.PHYS.ZS",
                               "SH.MED.NUMW.P3",
                               "SH.MED.BEDS.ZS",
                               "IQ.CPA.PROT.XQ",
                               "IQ.CPA.PADM.XQ",
                               "SI.POV.GINI",
                               "SH.DTH.COMM.ZS",
                               "SH.MED.CMHW.P3",
                               "SH.XPD.CHEX.PP.CD",
                               "SH.STA.HYGN.ZS",
                               "SP.POP.65UP.TO.ZS",
                               "SP.URB.TOTL.IN.ZS",
                               "EN.POP.SLUM.UR.ZS",
                               "per_si_allsi.cov_pop_tot"
                               
                               ), start = 1960, end = 2018, extra = TRUE)
  write.csv(wdi_dat, "data/wdi_dat.csv", row.names = FALSE)
} else {
  wdi_dat <- read_csv("data/wdi_dat.csv")
}

#lattest value per country
wdi_agg <- wdi_dat %>% 
            filter(region != "Aggregates") %>%
            mutate(longitude = as.numeric(as.character(longitude)),
                   latitude = as.numeric(as.character(latitude))) %>%
            arrange(iso2c, country, year) %>%
            group_by(iso2c, iso3c, region) %>%
            summarise_if(is.numeric, ~dplyr::last(na.omit(.))) %>%
            ungroup()

wdi_agg %>% plot_missing()
#select only vars with <11% missing values
vars <- map_df(wdi_agg, ~sum(is.na(.)) / length(.) * 100)  %>%
          gather() %>%
          filter(value < 11 ) %>%
          pull(key)

wdi_agg <- wdi_agg %>% select(all_of(vars))

#combine timeseries and wdia data
train <- train %>% 
         left_join(wdi_agg, by ="iso3c")

test <- test %>% 
         left_join(wdi_agg, by ="iso3c")

#calculaute per 100K
k <- 10 ^ 5
train <- train %>%
         mutate(Fatalities_per_100K = deaths / SP.POP.TOTL * k,
                ConfirmedCases_per_100K = confirmed / SP.POP.TOTL * k,
                Recovered_per_100K = recovered / SP.POP.TOTL * k,
                )


train %>% 
  filter(date == max(date)) %>%
  select(iso2c, confirmed) %>%
  gvisGeoChart(locationvar = "iso2c", 
                 colorvar = "confirmed",
                 options = list(projection="kavrayskiy-vii",
                              colorAxis="{colors:['#91BFDB', '#FC8D59']}",
                              gvis.editor="Choose Region")) %>%
  plot()




train %>% 
  filter(!is.na(iso2c)) %>%
  filter(date == max(date)) %>%
  select(iso2c, confirmed, ConfirmedCases_per_100K, deaths, Fatalities_per_100K, recovered,  Recovered_per_100K) %>%
  gvisIntensityMap() %>%
  plot()



Motion <- gvisMotionChart(train %>%
                            select(-timestamp, -latitude, -longitude),                       ,
                        idvar="country",
                        xvar ="confirmed",
                        yvar = "deaths",
                        timevar="date")
#Motion$html$caption=""
plot(Motion)

make_scatter <- function(x, y, xlog = TRUE, ylog = TRUE){
  plot <- train %>%
    filter(date == max(date)) %>%
    ggplot(aes_string( y = y,  x = x)) +
    geom_jitter() 
  if(ylog){
   plot <- plot +  scale_y_log10(breaks = trans_breaks("log10", function(x) 10^x),
                labels = trans_format("log10", math_format(10^.x)))
  }
  if(xlog){
    plot <- plot +  scale_x_log10(breaks = trans_breaks("log10", function(x) 10^x),
                labels = trans_format("log10", math_format(10^.x)))
  }
return(plot)
}

wdi <- names(wdi_agg)[5 : (ncol(wdi_agg) - 2)]
scatter_cases <- map(wdi,make_scatter, "confirmed")

n <- length(scatter_cases)
nCol <- floor(sqrt(n))
do.call("grid.arrange", c(scatter_cases, ncol = nCol))

scatter_fatalities <- map(wdi, make_scatter, "deaths", ylog = TRUE)

n <- length(scatter_fatalities)
nCol <- floor(sqrt(n))
do.call("grid.arrange", c(scatter_fatalities, ncol = nCol))

train %>% 
  filter(date == max(date)) %>%
    select(-c(days_since_global_outbreak ,Fatalities_per_100K, ConfirmedCases_per_100K, year )) %>%
    select(deaths, confirmed, everything()) %>%
  drop_na() %>%
  select_if(is.numeric) %>%
  ggpairs()

train %>% 
  filter(date == max(date)) %>%
  select(-c(days_since_global_outbreak ,Fatalities_per_100K, ConfirmedCases_per_100K, year, Recovered_per_100K, longitude, latitude )) %>%
  drop_na() %>%
  select_if(is.numeric) %>%
  cor() %>%
  corrplot(., method = "number")

```
# Goverment Interventions
```{r}
#https://github.com/joachim-gassen/tidycovid19


gov <- read_csv("data/gov.csv")

#download new data if available
if(max(gov$timestamp) < today() - days(1) ){

  gov_new <- download_acaps_npi_data() 
  
  #additional check
  if(nrow(gov_new) > nrow(gov)){
  gov <- gov_new
  rm(gov_new)
  write_csv(gov, "data/gov.csv")
  }
}

gov$date_implemented <- as.Date(gov$date_implemented)


gov %>% 
  count(category) %>%
  ggplot(aes(y = n, x = reorder(category, n))) +
  geom_bar(stat = "identity") +
  ggtitle("Government Intervention Categories") + 
  xlab("") +
  coord_flip() +
  ggtitle("Overview Categories Government Inverventions")

gov %>% 
  count(measure) %>%
  ggplot(aes(y = n, x = reorder(measure, n))) +
  geom_bar(stat = "identity") +
  ggtitle("Government Measures") + 
  xlab("") +
  coord_flip() +
  ggtitle("Overview Measures")


gov %>% count(category, date_implemented) %>%
  ggplot(aes(x = date_implemented, y = n, fill = category)) + 
  geom_col() + 
  xlab("Date") +
  ylab("Number of Interventions") +
  theme(legend.position="bottom") +
  ggtitle("Timeline Government Interventions")


  train %>%
              select(iso3c, iso2c, date, region, days_since_first_case) %>%
              inner_join(gov %>% count(category, date_implemented, iso3c), 
                         by = c("iso3c", "date" = "date_implemented")) %>%
  group_by(days_since_first_case, category) %>%
  summarise(n = sum(n)) %>%
  ggplot(aes(x = days_since_first_case, y = n, fill = category)) +
  geom_col() + 
  scale_fill_tableau() +
  ylab("Number of Interventions") + 
  xlab("Days since first case detected") +
  ggtitle("Government Intervention since first case detected in country")

#wide format government intervention

categories_list <- unique(gov$category)
 
#Median Growth Rate of different government measures
measures_plot1 <- map(categories_list, ~
train %>%
              select(iso3c, iso2c, date, region, days_since_first_case, confirmed) %>%
              left_join(gov %>% group_by(category,iso3c) %>% 
              filter(category == .x) %>%         
  summarise(n = n(), date_implemented =  min(date_implemented,na.rm =TRUE)), 
                         by = c("iso3c")) %>%
  group_by(iso2c) %>%
  mutate(ConfirmedCases_ma = rollapply(confirmed, width = 7,
                                       FUN = sum, align = "right", fill =NA),
         growthrate = ConfirmedCases_ma / lag(ConfirmedCases_ma)- 1,
         doubling_time = log(2) / log(growthrate + 1)) %>%
  filter(!is.na(growthrate)) %>%
  mutate(measure_implemented = case_when(is.na(date_implemented) ~ "not implemented",
         date < date_implemented ~ "not implemented",
         TRUE ~ "implemented")) %>%
  group_by(measure_implemented, days_since_first_case) %>%
  summarise(mean = mean(growthrate),
            std_err = sd(growthrate)/sqrt(n()),
             n = n()) %>%
  filter(n > 5 & days_since_first_case < 40 ) %>%
    ggplot(aes(x = days_since_first_case, y = mean, color =measure_implemented )) +
    geom_pointrange(
      aes(ymin = mean-1.96*std_err, ymax = mean+1.96*std_err),
      position=position_dodge(0.4)
    ) +
    labs(
      x = "Days since first case detected",
      y = "Growth Rate Confirmed Cases",
      color = .x
    ) + 
    theme_minimal() + 
    theme(
      legend.position = c(0.75, 0.75),
      plot.title.position = "plot", 
      plot.caption.position =  "plot",
      plot.caption = element_text(hjust = 0),
      axis.title.x = element_text(hjust = 1),
      axis.title.y = element_text(hjust = 1),
    ) +
    scale_y_continuous(labels = scales::percent) +
   scale_color_tableau()
)

n <- length(measures_plot1)
nCol <- floor(sqrt(n))
do.call("grid.arrange", c(measures_plot1, ncol = nCol))

######################################################
###Box plot of growth rate by days implemented
measure_plot3 <- map(categories_list, ~ train %>%
  select(iso3c, iso2c, date, region, days_since_first_case, confirmed) %>%
  left_join(gov %>% group_by(category,iso3c) %>% 
              filter(category == .x) %>%         
              summarise(n = n(), date_implemented =  min(date_implemented,na.rm =TRUE)), 
            by = c("iso3c")) %>%
  group_by(iso2c) %>%
  mutate(ConfirmedCases_ma = rollapply(confirmed, width = 7,
                                       FUN = sum, align = "right", fill =NA),
         growthrate = ConfirmedCases_ma / lag(ConfirmedCases_ma)- 1,
         doubling_time = log(2) / log(growthrate + 1)) %>%
  filter(!is.na(growthrate)) %>%
  ungroup() %>%
  mutate(days_implemented = difftime(date, date_implemented, units = "days")) %>%
  filter(days_implemented >= 0 & days_implemented < 40)  %>%
  ggplot(aes(x = factor(days_implemented), y =  growthrate)) + 
  geom_boxplot() +
  xlab( paste0("Days ", .x, " is in place" )) +
  ylab("Growth Rate Confirmed Cases") +
  scale_y_continuous(labels = scales::percent)
)

n <- length(measure_plot3)
nCol <- floor(sqrt(n))
do.call("grid.arrange", c(measure_plot3, ncol = nCol))
######
measures_list <- unique(gov$measure)

measure_plot4 <- map(measures_list, ~ train %>%
  select(iso3c, iso2c, date, region, days_since_first_case, confirmed) %>%
  left_join(gov %>% group_by(measure, iso3c) %>% 
              filter(measure == .x) %>%         
              summarise(n = n(), date_implemented =  min(date_implemented,na.rm =TRUE)), 
            by = c("iso3c")) %>%
  group_by(iso2c) %>%
  mutate(ConfirmedCases_ma = rollapply(confirmed, width = 7,
                                       FUN = sum, align = "right", fill =NA),
         growthrate = ConfirmedCases_ma / lag(ConfirmedCases_ma)- 1,
         doubling_time = log(2) / log(growthrate + 1)) %>%
  filter(!is.na(growthrate)) %>%
  ungroup() %>%
  mutate(days_implemented = difftime(date, date_implemented, units = "days")) %>%
  filter(days_implemented >= 0 & days_implemented < 40)  %>%
  ggplot(aes(x = factor(days_implemented), y =  growthrate)) + 
  geom_boxplot() +
  xlab( paste0("Days ", .x, " is in place" )) +
  ylab("Growth Rate Confirmed Cases") +
  scale_y_continuous(labels = scales::percent)
)

n <- length(measure_plot4)
nCol <- floor(sqrt(n))
do.call("grid.arrange", c(measure_plot4, ncol = nCol))

 

```


# Time Series Plots
```{r ts}

train_ts <- train %>%   
                as_tsibble(
                index = date,
                key = country
              )

confirmed_cases_features <- train_ts %>%
                            features(confirmed, feat_stl)

confirmed_cases_features %>%
  select(2 : 10) %>%
  ggpairs()

pcs <- train_ts %>%
      features(confirmed, feat_stl) %>%
      select(2 : 10) %>%
      prcomp(scale = TRUE) %>%
broom::augment(confirmed_cases_features)


pcs %>% ggplot(aes(x=.fittedPC1, y=.fittedPC2)) +
geom_point() + theme(aspect.ratio=1)


outlier <- pcs %>%
  filter(.fittedPC1 == max(.fittedPC1)) %>% 
  pull(country)

train_ts %>%
  filter(country == outlier) %>%
  feasts::autoplot(confirmed)

#Decompose a time series in preparation for anomaly detection
# Seasonal-Trend-Loess (STL) Decomposition in the form of “observed”, “season”, “trend” and “remainder”
set.seed(123)
sampled_id <- unique(train$country )[sample(1 : length(unique(train$country)), 10)]
sampled_id <- c(sampled_id, "Italy", "France", "Germany", "Sweden", "US", "Thailand", "China", "Afghanistan")

#show subset of countries
train %>% 
  filter(country %in% sampled_id) %>%
  group_by(country) %>%
    arrange(date) %>%
    mutate(confirmed = log(confirmed + 1 )) %>%
    time_decompose(confirmed) %>%
    anomalize(remainder) %>%
    time_recompose() %>%
    plot_anomalies(ncol = 3, alpha_dots = 0.3)
# the STL has some problems to detect the exponential trend in some cases





```
# Feature Engineering
## WDI
```{r}


train  %>% plot_missing()



#test <- test %>% left_join(wdi_agg %>% select(-c(year, region)), by = "iso2c")

```
## Goverment Inventions
```{r}
gov_wide <- gov %>%
            filter(is.na(admin_level_name)) %>%
            mutate(category = str_trim(str_replace_all(category, " ", "_")),
                   category = str_replace_all(category, "[[:punct:]]", "")) %>%
            group_by(iso3c, category) %>%
            summarise(date_implemented = min (date_implemented, na.rm = TRUE)) %>%
            ungroup() %>%
            pivot_wider(names_from = category, values_from = date_implemented) 

categories_list <-  str_trim(str_replace_all(categories_list, " ", "_")) %>%
                    str_replace_all(., "[[:punct:]]", "")

measures_list <-    str_trim(str_replace_all(measures_list, " ", "_")) %>%
                    str_replace_all(., "[[:punct:]]", "") %>%
                    str_to_lower(.)

gov_measures <-  gov %>%
                 #measure should be at leat 14 days in place
                 mutate(date_implemented = date_implemented + days(14),
                        measure = str_to_lower(str_trim(str_replace_all(measure, " ", "_"))),
                        measure = str_replace_all(measure, "[[:punct:]]", "")) %>%
                 count(measure, date_implemented, iso3c) %>%
                 rename(distance_measures = n) %>%
                 pivot_wider(names_from = measure, values_from = distance_measures)

overall_distancing_measures <- gov %>%
                              #measure should be at leat 14 days in place
                              mutate(date_implemented = date_implemented + days(14)) %>%
                              filter(category %in% c("Social distancing",
                                                     "Movement restrictions", "Lockdown")) %>%
                              count(date_implemented, iso3c) %>%
                              rename(distance_measures = n)


train <- train %>% 
         left_join(gov_measures, c("iso3c", "date" = "date_implemented")) %>%
         mutate_at(.vars = measures_list, ~  cumsum(coalesce(., 0L)) ) %>%
         left_join(overall_distancing_measures, by = c("iso3c", "date" = "date_implemented")) %>%
         group_by(country) %>%
         mutate(distance_measures = cumsum(coalesce(distance_measures, 0L)))

test <- test %>% 
         left_join(gov_measures, c("iso3c", "date" = "date_implemented")) %>%
         mutate_at(.vars = measures_list, ~  cumsum(coalesce(., 0L)) ) %>%
         left_join(overall_distancing_measures, by = c("iso3c", "date" = "date_implemented")) %>%
         group_by(country) %>%
         mutate(distance_measures = cumsum(coalesce(distance_measures, 0L))) %>%
         ungroup()


```

## Lagged Features
```{r}
#https://gist.github.com/drsimonj/2038ff9f9c67063f384f10fac95de566

lag <- 14
lags <- seq(lag)
lag_names <- paste("diff_cases_lag", formatC(lags, width = nchar(max(lags)), flag = "0"), 
                   sep = "_")
lag_functions_cases <- setNames(paste("dplyr::lag(., ", lags, ")"), lag_names)

train <- train %>%
        group_by(country) %>%
        arrange(country, date) %>%
        mutate(log_cases = log(confirmed + 1),
                log_cases = log_cases - lag(log_cases)) %>%
        mutate_at(vars(log_cases), funs_(lag_functions_cases)) %>%
        ungroup()



#combine lagged features with training data
train_lagged <- train %>% 
                filter(date >= min(date) + days(lag + 1)) %>%
                arrange(date, country)
```
# ML Models
# Recursive Strategy
https://www.statworx.com/de/blog/time-series-forecasting-with-random-forest/
```{r}
#columns to remove 
col_rem <- c("country", "iso3c", "date", "deaths", "timestamp", "day_of_first_case",
              "distance_measures", "iso2c", "year", "confirmed", "recovered", "ConfirmedCases_per_100K", "Fatalities_per_100K","Recovered_per_100K")

train_cases <- train_lagged %>%
               select(- all_of(col_rem))
         
                         
recipe_confirmedcases <- recipe(log_cases ~ ., train_cases) %>%
  step_medianimpute(all_numeric(), -all_outcomes()) %>%
  step_center(all_numeric(), -all_outcomes()) %>%
  step_scale(all_numeric(), -all_outcomes()) %>%
  step_zv(all_predictors(), -all_outcomes()) %>%
  step_dummy(all_nominal(), -all_outcomes()) %>%
  prep(data = train_cases)   
###
training_set <-  train_lagged  %>%
  filter(date <= max(date) - days(period)) %>%
  select(- all_of(col_rem)) %>%
  bake(recipe_confirmedcases, new_data = .) %>%
  select(log_cases, everything())

test_set <- train_lagged %>%
  filter( date > max(date)- days(period)) %>%
  mutate(days_since_first_case = ifelse(day_of_first_case >= max(date) - days(period), -1,   days_since_first_case)) %>%
  select(- all_of(col_rem)) %>% 
  bake(recipe_confirmedcases, new_data = .) %>%
  select(log_cases, everything()) 

#show Folds (Date Column is required)
n_countries <- train_lagged %>% distinct(country) %>% nrow()
init <- 27
rolling_folds <- train_lagged  %>%
                 filter(date <= max(date) - days(period)) %>%
                 rolling_origin(.,
                                initial =  init * n_countries,
                                assess =  7 * n_countries,
                                skip = 7 * n_countries,
                                cumulative = TRUE)

#print folds using the date column
for(i in 1: length(rolling_folds$splits)){
  model_from <- rolling_folds$splits[[i]] %>% analysis() %>% pull(date) %>% min()
  model_to <- rolling_folds$splits[[i]] %>% analysis() %>% pull(date) %>% max()
  assesment_from <- rolling_folds$splits[[i]] %>% assessment() %>% pull(date) %>% min()
  assesment_to <- rolling_folds$splits[[i]] %>% assessment() %>% pull(date) %>% max()
  print(paste0("Fold ", i))
  print(paste0("Modelling ", model_from, " - ", model_to ))
  print(paste0("Assesment ", assesment_from, " - ", assesment_to ))

}
####


#Create Folds for modeling excluding date column
n_countries <- train %>% distinct(country) %>% nrow()
rolling_folds <- training_set %>%
                 rolling_origin(.,
                                initial =  init * n_countries,
                                assess =  7 * n_countries,
                                skip = 7 * n_countries,
                                cumulative = TRUE)

# xgboost – Model Spec
xgboost_model <- boost_tree(
        mode       = "regression", 
        trees      = tune(), 
        min_n      = tune(), 
        tree_depth = tune(), 
        learn_rate = tune()
    ) %>%
    set_engine("xgboost", objective = "reg:squarederror")

xgboost_model


#xgboost – Grid Spec
xgboost_params <- parameters(trees(), min_n(), tree_depth(), learn_rate())
xgboost_params




set.seed(123)
xgboost_grid <- grid_max_entropy(xgboost_params, size = 4)
xgboost_grid

#train a challenger model once a week
 if(wday(today(), week_start = 1) == 1){
  #xgboost – Hyperparameter Tuning
  challenger_tune <- tune_grid(log_cases ~ ., 
                        model =  xgboost_model,
                        resamples = rolling_folds,
                        metrics   = metric_set(mae, mape, rmse, rsq),
                        grid = xgboost_grid)
  saveRDS(xgb_tune, "challenger_model.rds")
  
  xgb_tune <- readRDS("model.rds")
}

#Compare and Select Best Model
xgb_tune %>% show_best("mae", n = 3, maximize = FALSE)
xgb_tune %>% select_best("mae", maximize = FALSE)

params_xgboost_best <- xgb_tune %>% 
    select_best("mae", maximize = FALSE)

#Finalize the Model for testing
xgboost_finalized <- xgboost_model %>% 
    finalize_model(params_xgboost_best)

xgboost_fit <- xgboost_finalized %>%
                fit(log_cases ~.,
                    training_set)

vip(xgboost_fit) +
    labs(title = "XGBoost Model Importance")

#onstep ahead forecast
#last week for testing
test_dates <-train_lagged %>% filter(date > max(date)- days(period)) %>% distinct(date)
test_data <- train_lagged %>%
  filter( date > max(date) - days(period + lag)) 

i <- 1
for(i in 1 : nrow(test_dates)){
  new_data <- test_data %>%
              filter(date > test_dates$date[i] - days(period + 1) & date <= test_dates$date[i])
  
   new_data <- new_data %>% 
                group_by(country) %>% 
                mutate_at(vars(log_cases), funs_(lag_functions_cases)) %>%
                ungroup() %>%
                filter(date == test_dates$date[i]) %>%
                bake(recipe_confirmedcases, new_data = .) %>%
                select(log_cases, everything())
   
                
  pred <-  xgboost_fit %>% predict(new_data = new_data) %>% pull(.pred)
  
  test_data$log_cases[test_data$date == test_dates$date[i]] <- pred
}
#Calculating the cumlative values

#lastvalue
last_value <- test_data %>%
              filter(date == test_dates$date[1] - days(1)) %>%
              mutate(last_value = confirmed + 1) %>%
              select(country, last_value)

test_data <- test_data %>%
              filter(date >= test_dates$date[1]) %>%
              arrange(country, date) %>%
              group_by(country) %>%
              mutate(log_cases = exp(cumsum(log_cases))) %>%
              ungroup() %>%  
              inner_join(last_value, by = "country") %>%
              mutate(pred_confirmed = log_cases * (last_value - 1))

test_data %>% 
filter(country == "Germany") %>%
ggplot(aes(x = date)) +
  geom_line(aes(y = confirmed)) +
  geom_line(aes(y = pred_confirmed), color = "blue")

test_data %>% 
  group_by(date) %>%
  summarise(confirmed = sum(confirmed),
            pred_confirmed = sum(pred_confirmed)) %>%
ggplot(aes(x = date)) +
  geom_line(aes(y = confirmed)) +
  geom_line(aes(y = pred_confirmed), color = "blue")


reg_metrics <- metric_set(rmse, mae, mape)

perf_ml_cases_recursive <-   test_data %>%
                              group_by(country) %>%
                              reg_metrics(truth = confirmed, estimate = pred_confirmed) %>%
                              mutate(.metric = toupper(.metric),
                                     .model = "recursive_xgb") %>%
                              pivot_wider(names_from = .metric, values_from = .estimate) %>%
                              select(-.estimator)

perf_ml_cases_recursive %>% 
                    ggplot(aes(x = MAPE)) + 
                    geom_histogram(bins = 50)

##Final Model (Full Dataset)
training_set_full <-  train_lagged  %>%
  bake(recipe_confirmedcases, new_data = .) %>%
  select(log_cases, everything())

xgboost_fit_final <- xgboost_finalized %>%
                     fit(log_cases ~.,
                     training_set)
#Feature Importance
vip(xgboost_fit_final) +
    labs(title = "XGBoost Model Importance") 

###########################################################################
#Final Prediction on newdata
#onstep ahead forecast
test_dates <- test  %>% distinct(date)
test_data <- train_lagged %>%
  filter( date > max(date) - days(lag)) %>%
  bind_rows(test)
i <- 1

for(i in 1 : nrow(test_dates)){
  new_data <- test_data %>%
              filter(date > test_dates$date[i] - days(period) & date <= test_dates$date[i])
   new_data <- new_data %>% 
                group_by(country) %>% 
                mutate_at(vars(log_cases), funs_(lag_functions_cases)) %>%
                ungroup() %>%
                filter(date == test_dates$date[i]) %>%
                bake(recipe_confirmedcases, new_data = .) %>%
                select(log_cases, everything())
                
  pred <-  xgboost_fit_final %>% predict(new_data = new_data) %>% pull(.pred)
  
  test_data$log_cases[test_data$date == test_dates$date[i]] <- pred
}
#Calculating the cumlative values
#lastvalue
last_value <- test_data %>%
              filter(date == test_dates$date[1] - days(1)) %>%
              mutate(last_value = confirmed + 1) %>%
              select(country, last_value)

cases_pred_ml <- test_data %>%
              filter(date >= test_dates$date[1]) %>%
              arrange(country, date) %>%
              group_by(country) %>%
              mutate(log_cases = exp(cumsum(log_cases))) %>%
              ungroup() %>%  
              inner_join(last_value, by = "country") %>%
              mutate(pred_confirmed = log_cases * (last_value - 1))

cases_pred_ml %>% 
filter(country == "Germany") %>%
ggplot(aes(x = date)) +
  geom_line(aes(y = confirmed)) +
  geom_line(aes(y = pred_confirmed), color = "blue")



```
## Direct Strategy
```{r}

period
n_countries
lag


X_test <- training_set

train_lagged$
  
xgboost_fit_final <- xgboost_finalized %>%
  fit_xy(x = lending_club[, c("funded_amnt", "int_rate")],
         y = lending_club$Class)


#challenger models once a week to check if it has better performance  

```
# Time Series Models ConfirmedCases
```{r}
if(F){
period <- 7

length_series <- train %>% 
                  filter(date <= max(date) - days(period)) %>%
                  group_by(country) %>%
                  summarise( length_series = max(days_since_first_case),
                              ttl_distance_measures = sum(distance_measures))



train_ts <- train %>%
            select(country, date, confirmed, distance_measures) %>%
             as_tsibble(
                index = date,
                key = country
              )


train_model_long <- train_ts %>%
                    filter(date <= max(date) - days(period)) %>%
                    inner_join(length_series, by = "country") %>%
                    filter(length_series > 7) %>%
                    model(
                      ETS = ETS(confirmed),
                      ARIMA = ARIMA(confirmed),
                      ETS_LOG = ETS(log(confirmed + 1)),
                      ARIMA_LOG = ARIMA(log(confirmed + 1)),
                      NAIVE = NAIVE(confirmed),
                      #NNETAR = NNETAR(confirmed),
                      SNAIVE = SNAIVE(confirmed))

train_forecast_long <- train_model_long %>%  
                  forecast(h = paste0(period, " days"))

best_model_long <- train_forecast_long %>%
  fabletools::accuracy(train_ts) %>%
  arrange(country, RMSE) %>%
  group_by(country) %>%
  slice(1)
##########################################################################
#regarima
train_model_regarima <- train_ts %>%
                        filter(date <= max(date) - days(period)) %>%
                        inner_join(length_series, by = "country") %>%
                        filter(length_series > 7 & ttl_distance_measures > 0) %>%
                        model(regarima = ARIMA(confirmed ~ distance_measures))

new_data <- train_ts %>%
  filter(date == max(date) - days(period)) %>%
  inner_join(length_series, by = "country") %>%
  filter(length_series > 7 & ttl_distance_measures > 0) %>%
  as_tibble() %>%
  select(country, distance_measures)


new_data <- train_ts %>%
              filter(date == max(date) - days(period)) %>%
              new_data(., period) %>%
              inner_join(new_data, by = "country")

train_forecast_regarima <- train_model_regarima %>% forecast(new_data)

best_model_regarima <- train_forecast_regarima %>%
                       fabletools::accuracy(train_ts) 


####################################################  

# train_model_short <- train_ts %>%
#   filter(Date <= max(Date) - days(period)) %>%
#   inner_join(length_series, by = "country_id") %>%
#   filter(length_series <= 7) %>%
#   model(
#     ETS = ETS(ConfirmedCases),
#     ARIMA = ARIMA(ConfirmedCases),
#     NAIVE = NAIVE(ConfirmedCases),
#     SNAIVE = SNAIVE(ConfirmedCases)
#   )



# train_forecast_short <- train_model_short %>%  
#                         forecast(h = paste0(period, " days"))

# best_model_short<- train_forecast_short %>%
#   fabletools::accuracy(train_ts) %>%
#   arrange(country_id, RMSE) %>%
#   group_by(country_id) %>%
#   slice(1)

best_model_cases <- best_model_long %>%
                    #bind_rows(best_model_short) %>%
                    bind_rows(best_model_regarima) %>%
                    arrange(country, RMSE) %>%
                    group_by(country) %>%
                    slice(1)

write.csv(best_model_cases, "train_performance.csv", row.names = FALSE)
} else {
best_model_cases <- read.csv("train_performance.csv", stringsAsFactors = FALSE)
}
best_model_cases %>% ggplot(aes(x = MAE)) + 
                    geom_histogram(bins = 50) +
                    scale_x_log10()

best_model_cases %>% ggplot(aes(x = MAPE)) + 
  geom_histogram(bins = 50)


best_model_cases %>% ggplot(aes(x = .model)) + geom_bar()
                    
#fit all models on whole dataset and forecast number of days in test set
period <-  as.numeric(difftime(max(test$date), min(test$date), units = "days")) + 1 

pred_best_model_ts <- function(x, target = "confirmed"){
model_country <- best_model_cases %>% filter(.model == x) %>% pull(country)
#log models
  if(str_detect("ETS_LOG","LOG")){
    x <- str_replace(x,"_LOG","")
      model <- train_ts %>%
        filter(country %in% model_country ) %>%
        model(x = eval(parse(text = x))(log(!! sym(target) + 1))) %>% 
        forecast(h = paste0(period, " days")) %>%
        as.data.frame() %>%
        mutate(.model = x) %>%
        select(1 : 4)
  } else {
        model <- train_ts %>%
        filter(country %in% model_country ) %>%
        model(x = eval(parse(text = x))(!! sym(target))) %>% 
        forecast(h = paste0(period, " days")) %>%
        as.data.frame() %>%
        mutate(.model = x) %>%
        select(1 : 4)
    
  }
return(model)
}



if(F){
  ##pred regarima best_model
regarima_coutries <- best_model_cases %>%
                      filter(.model =="regarima") %>%
                      pull(country)

train_model_regarima <- train_ts %>%
                        filter(country %in% regarima_coutries) %>%
                        model(regarima = ARIMA(ConfirmedCases ~ distance_measures))


new_data <- train_ts %>%
  filter(date == max(date) & country %in% regarima_coutries) %>%
  as_tibble() %>%
  select(country, distance_measures)


new_data <- train_ts %>%
              filter(date == max(date)) %>%
              new_data(., period) %>%
              inner_join(new_data, by = "country")

regarima_pred <- train_model_regarima %>%
                           forecast(new_data) %>%
                           as_tibble() %>%
                           select(1 : 4)
#remaing models   
  
  final_pred <- map_df(
    unique(best_model_cases$.model)[unique(best_model_cases$.model) != "regarima"], pred_best_model_ts, "confirmed")
  
final_pred <-  final_pred %>% 
                bind_rows(regarima_pred)
    write.csv(final_pred, "prediction_ts_confirmedcases.csv", row.names = FALSE)
} else {
 final_pred_cases <- read_csv("prediction_ts_confirmedcases.csv")
}


```

# Model Comparison
```{r}

best_model_cases <- best_model_cases %>% 
                    bind_rows(perf_ml_cases_recursive) %>%
                    arrange(country, RMSE) %>%
                    group_by(country) %>%
                    slice(1)

best_model_cases %>% 
  ggplot(aes(x = .model)) +
  geom_bar() + 
  ggtitle("Best Model Confirmed Cases")


```
# Submission
```{r}
# Confirmed Cases
best_ts_cases <- final_pred_cases %>%
inner_join(
best_model_cases  %>% filter(.model != "automl") %>% select(country_id), by = "country_id") %>%
select(country_id, Date, ConfirmedCases)  

best_ml_cases <- cases_pred_auto_ml %>%
inner_join(
best_model_cases  %>% filter(.model == "automl") %>% select(country_id), by = "country_id") %>%
select(country_id, Date, ConfirmedCases = ConfirmedCases_pred)  


pred_cases <-  best_ts_cases %>% bind_rows(best_ml_cases)

#Fatalities

best_ts_fatalities <- final_pred_fatalities %>%
inner_join(
best_model_fatalities  %>% filter(.model != "automl") %>% select(country_id), by = "country_id") %>%
select(country_id, Date, Fatalities)  

best_ml_fatalities <- fatalities_pred_auto_ml %>%
inner_join(
best_model_fatalities  %>% filter(.model == "automl") %>% select(country_id), by = "country_id") %>%
select(country_id, Date, Fatalities = Fatalities_pred)  


pred_fatalities <-  best_ts_fatalities %>% bind_rows(best_ml_fatalities)


submission <- test %>% select(ForecastId, country_id, Date) %>%
  left_join(train %>% select(country_id, Date, ConfirmedCases, Fatalities), by = c("Date", "country_id")) %>%
 left_join(pred_cases, by = c("Date", "country_id")) %>%
  left_join(pred_fatalities, by = c("Date", "country_id")) %>%
  mutate(ConfirmedCases = coalesce(ConfirmedCases.x, ConfirmedCases.y),
         Fatalities = coalesce(Fatalities.x, Fatalities.y)) %>%
  select(ForecastId, ConfirmedCases, Fatalities)

write.csv(submission, "final_pred.csv", row.names = FALSE)

```